{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: ['0' '1' '1' ... '9752' '9752' '9753']\n",
      "  [0 3 7 ... 1 1 4]\n",
      " TEST: ['2' '5' '5' ... '9726' '9729' '9738']\n",
      "  [3 7 0 ... 2 3 3]\n",
      "TRAIN: ['2' '3' '3' ... '9752' '9752' '9752']\n",
      "  [3 2 6 ... 0 1 1]\n",
      " TEST: ['0' '1' '1' ... '9750' '9751' '9753']\n",
      "  [0 3 7 ... 0 7 4]\n",
      "TRAIN: ['0' '1' '1' ... '9752' '9752' '9753']\n",
      "  [0 3 7 ... 1 1 4]\n",
      " TEST: ['7' '7' '16' ... '9744' '9744' '9744']\n",
      "  [9 9 6 ... 0 0 0]\n",
      "TRAIN: ['0' '1' '1' ... '9750' '9751' '9753']\n",
      "  [0 3 7 ... 0 7 4]\n",
      " TEST: ['3' '3' '6' ... '9752' '9752' '9752']\n",
      "  [2 6 1 ... 0 1 1]\n",
      "TRAIN: ['0' '1' '1' ... '9752' '9752' '9753']\n",
      "  [0 3 7 ... 1 1 4]\n",
      " TEST: ['4' '4' '4' ... '9735' '9742' '9749']\n",
      "  [1 1 1 ... 1 3 0]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# load json: modify the path to your own ‘train.json’ file\n",
    "annotation = '/opt/ml/pseduo_dataset/train.json'\n",
    "\n",
    "with open(annotation) as f: data = json.load(f)\n",
    "\n",
    "var = [(ann['image_id'], ann['category_id']) for ann in data['annotations']]\n",
    "X = np.ones((len(data['annotations']),1))\n",
    "y = np.array([v[1] for v in var])\n",
    "groups = np.array([v[0] for v in var])\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=411)\n",
    "\n",
    "for train_idx, val_idx in cv.split(X, y, groups):\n",
    "    print(\"TRAIN:\", groups[train_idx])\n",
    "    print(\" \", y[train_idx])\n",
    "    print(\" TEST:\", groups[val_idx])\n",
    "    print(\" \", y[val_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General trash</th>\n",
       "      <th>Paper</th>\n",
       "      <th>Paper pack</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Glass</th>\n",
       "      <th>Plastic</th>\n",
       "      <th>Styrofoam</th>\n",
       "      <th>Plastic bag</th>\n",
       "      <th>Battery</th>\n",
       "      <th>Clothing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training set</th>\n",
       "      <td>16.05%</td>\n",
       "      <td>26.97%</td>\n",
       "      <td>4.25%</td>\n",
       "      <td>3.99%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.51%</td>\n",
       "      <td>5.22%</td>\n",
       "      <td>23.89%</td>\n",
       "      <td>0.70%</td>\n",
       "      <td>2.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train - fold0</th>\n",
       "      <td>15.87%</td>\n",
       "      <td>27.82%</td>\n",
       "      <td>4.35%</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>4.00%</td>\n",
       "      <td>12.43%</td>\n",
       "      <td>5.10%</td>\n",
       "      <td>23.73%</td>\n",
       "      <td>0.70%</td>\n",
       "      <td>2.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val - fold0</th>\n",
       "      <td>16.81%</td>\n",
       "      <td>23.39%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.50%</td>\n",
       "      <td>5.21%</td>\n",
       "      <td>12.82%</td>\n",
       "      <td>5.74%</td>\n",
       "      <td>24.58%</td>\n",
       "      <td>0.70%</td>\n",
       "      <td>2.37%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train - fold1</th>\n",
       "      <td>16.01%</td>\n",
       "      <td>27.16%</td>\n",
       "      <td>4.20%</td>\n",
       "      <td>4.01%</td>\n",
       "      <td>4.42%</td>\n",
       "      <td>12.50%</td>\n",
       "      <td>5.23%</td>\n",
       "      <td>23.85%</td>\n",
       "      <td>0.59%</td>\n",
       "      <td>2.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val - fold1</th>\n",
       "      <td>16.20%</td>\n",
       "      <td>26.21%</td>\n",
       "      <td>4.48%</td>\n",
       "      <td>3.93%</td>\n",
       "      <td>3.52%</td>\n",
       "      <td>12.53%</td>\n",
       "      <td>5.18%</td>\n",
       "      <td>24.04%</td>\n",
       "      <td>1.12%</td>\n",
       "      <td>2.78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train - fold2</th>\n",
       "      <td>15.82%</td>\n",
       "      <td>26.64%</td>\n",
       "      <td>4.22%</td>\n",
       "      <td>4.09%</td>\n",
       "      <td>4.38%</td>\n",
       "      <td>12.38%</td>\n",
       "      <td>5.34%</td>\n",
       "      <td>24.06%</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>2.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val - fold2</th>\n",
       "      <td>16.99%</td>\n",
       "      <td>28.27%</td>\n",
       "      <td>4.40%</td>\n",
       "      <td>3.60%</td>\n",
       "      <td>3.64%</td>\n",
       "      <td>13.05%</td>\n",
       "      <td>4.74%</td>\n",
       "      <td>23.23%</td>\n",
       "      <td>0.25%</td>\n",
       "      <td>1.84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train - fold3</th>\n",
       "      <td>16.21%</td>\n",
       "      <td>26.48%</td>\n",
       "      <td>4.38%</td>\n",
       "      <td>4.21%</td>\n",
       "      <td>4.09%</td>\n",
       "      <td>12.65%</td>\n",
       "      <td>5.10%</td>\n",
       "      <td>23.96%</td>\n",
       "      <td>0.77%</td>\n",
       "      <td>2.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val - fold3</th>\n",
       "      <td>15.44%</td>\n",
       "      <td>28.79%</td>\n",
       "      <td>3.78%</td>\n",
       "      <td>3.19%</td>\n",
       "      <td>4.78%</td>\n",
       "      <td>11.97%</td>\n",
       "      <td>5.70%</td>\n",
       "      <td>23.65%</td>\n",
       "      <td>0.43%</td>\n",
       "      <td>2.28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train - fold4</th>\n",
       "      <td>16.34%</td>\n",
       "      <td>26.72%</td>\n",
       "      <td>4.13%</td>\n",
       "      <td>3.79%</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>12.58%</td>\n",
       "      <td>5.34%</td>\n",
       "      <td>23.87%</td>\n",
       "      <td>0.62%</td>\n",
       "      <td>2.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val - fold4</th>\n",
       "      <td>14.84%</td>\n",
       "      <td>27.98%</td>\n",
       "      <td>4.77%</td>\n",
       "      <td>4.83%</td>\n",
       "      <td>4.03%</td>\n",
       "      <td>12.21%</td>\n",
       "      <td>4.72%</td>\n",
       "      <td>23.99%</td>\n",
       "      <td>1.02%</td>\n",
       "      <td>1.60%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              General trash   Paper Paper pack  Metal  Glass Plastic  \\\n",
       "training set         16.05%  26.97%      4.25%  3.99%  4.24%  12.51%   \n",
       "train - fold0        15.87%  27.82%      4.35%  3.87%  4.00%  12.43%   \n",
       "val - fold0          16.81%  23.39%      3.88%  4.50%  5.21%  12.82%   \n",
       "train - fold1        16.01%  27.16%      4.20%  4.01%  4.42%  12.50%   \n",
       "val - fold1          16.20%  26.21%      4.48%  3.93%  3.52%  12.53%   \n",
       "train - fold2        15.82%  26.64%      4.22%  4.09%  4.38%  12.38%   \n",
       "val - fold2          16.99%  28.27%      4.40%  3.60%  3.64%  13.05%   \n",
       "train - fold3        16.21%  26.48%      4.38%  4.21%  4.09%  12.65%   \n",
       "val - fold3          15.44%  28.79%      3.78%  3.19%  4.78%  11.97%   \n",
       "train - fold4        16.34%  26.72%      4.13%  3.79%  4.29%  12.58%   \n",
       "val - fold4          14.84%  27.98%      4.77%  4.83%  4.03%  12.21%   \n",
       "\n",
       "              Styrofoam Plastic bag Battery Clothing  \n",
       "training set      5.22%      23.89%   0.70%    2.18%  \n",
       "train - fold0     5.10%      23.73%   0.70%    2.13%  \n",
       "val - fold0       5.74%      24.58%   0.70%    2.37%  \n",
       "train - fold1     5.23%      23.85%   0.59%    2.03%  \n",
       "val - fold1       5.18%      24.04%   1.12%    2.78%  \n",
       "train - fold2     5.34%      24.06%   0.81%    2.26%  \n",
       "val - fold2       4.74%      23.23%   0.25%    1.84%  \n",
       "train - fold3     5.10%      23.96%   0.77%    2.15%  \n",
       "val - fold3       5.70%      23.65%   0.43%    2.28%  \n",
       "train - fold4     5.34%      23.87%   0.62%    2.32%  \n",
       "val - fold4       4.72%      23.99%   1.02%    1.60%  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check distribution\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def get_distribution(y):\n",
    "    y_distr = Counter(y)\n",
    "    y_vals_sum = sum(y_distr.values())\n",
    "\n",
    "    return [f'{y_distr[i]/y_vals_sum:.2%}' for i in range(np.max(y) +1)]\n",
    "\n",
    "distrs = [get_distribution(y)]\n",
    "index = ['training set']\n",
    "\n",
    "for fold_ind, (train_idx, val_idx) in enumerate(cv.split(X,y, groups)):\n",
    "    train_y, val_y = y[train_idx], y[val_idx]\n",
    "    train_gr, val_gr = groups[train_idx], groups[val_idx]\n",
    "\n",
    "    assert len(set(train_gr) & set(val_gr)) == 0 \n",
    "    distrs.append(get_distribution(train_y))\n",
    "\n",
    "    distrs.append(get_distribution(val_y))\n",
    "    index.append(f'train - fold{fold_ind}')\n",
    "    index.append(f'val - fold{fold_ind}')\n",
    "\n",
    "categories = [d['name'] for d in data['categories']]\n",
    "pd.DataFrame(distrs, index=index, columns = [categories[i] for i in range(np.max(y) + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 40869, 40870, 40871])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(cv.split(X,y, groups))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7793"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_gr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '1', ..., '9752', '9752', '9753'], dtype='<U21')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 이미지 파일 개수(80%):7790\n",
      "new_dataset_train 파일 개수:0\n",
      "val 이미지 파일 개수(20%):1949\n",
      "new_dataset_val 파일 개수:0\n",
      "train 이미지 파일 개수(80%):7789\n",
      "new_dataset_train 파일 개수:0\n",
      "val 이미지 파일 개수(20%):1950\n",
      "new_dataset_val 파일 개수:0\n",
      "train 이미지 파일 개수(80%):7793\n",
      "new_dataset_train 파일 개수:0\n",
      "val 이미지 파일 개수(20%):1946\n",
      "new_dataset_val 파일 개수:0\n",
      "train 이미지 파일 개수(80%):7791\n",
      "new_dataset_train 파일 개수:0\n",
      "val 이미지 파일 개수(20%):1948\n",
      "new_dataset_val 파일 개수:0\n",
      "train 이미지 파일 개수(80%):7793\n",
      "new_dataset_train 파일 개수:0\n",
      "val 이미지 파일 개수(20%):1946\n",
      "new_dataset_val 파일 개수:0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "origin_dataset_dir = '/opt/ml/pseduo_dataset'\n",
    "new_dataset_dir = '/opt/ml/skfold-pseduo'\n",
    "input_json_path = '/opt/ml/pseduo_dataset/train.json' #train.json 파일 경로\n",
    "val_ratio = 0.2\n",
    "\n",
    "\n",
    "for fold_ind, (train_idx, val_idx) in enumerate(cv.split(X,y, groups)):\n",
    "#json 파일 불러오기\n",
    "    with open(input_json_path, 'r') as json_reader:\n",
    "        dataset = json.load(json_reader)\n",
    "\n",
    "    images = dataset['images'] # dict에서 (key:images)의 values 불러오기\n",
    "    categories = dataset['categories']# dict에서 (key:catagories)의 values 불러오기\n",
    "    annotations = dataset['annotations']# dict에서 (key:annotations)의 values 불러오기\n",
    "    \n",
    "    train_gr, val_gr = groups[train_idx], groups[val_idx]\n",
    "\n",
    "    # image_ids = [x.get('id') for x in images] # get함수를 통해 dict에서 id값 추출\n",
    "    # image_ids.sort() # 정렬\n",
    "    # random.shuffle(image_ids) # 인덱스 섞기\n",
    "\n",
    "    # num_val = int(len(image_ids) * val_ratio)\n",
    "    # num_train = len(image_ids) - num_val\n",
    "\n",
    "    image_ids_val, image_ids_train = set(val_gr), set(train_gr)\n",
    "\n",
    "    num_train = len(image_ids_train)\n",
    "    num_val = len(image_ids_val)\n",
    "\n",
    "    #Image_id를 기준으로 train/val 나누기\n",
    "    train_images = [x for x in images if x.get('id') in image_ids_train]\n",
    "    val_images = [x for x in images if x.get('id') in image_ids_val]\n",
    "    train_annotations = [x for x in annotations if x.get('image_id') in image_ids_train]\n",
    "    val_annotations = [x for x in annotations if x.get('image_id') in image_ids_val]\n",
    "\n",
    "    #file_name 수정\n",
    "    for info in val_images:\n",
    "        name = info['file_name'].split('/')[1]\n",
    "        info['file_name'] = os.path.join('val',name)\n",
    "        \n",
    "    #나눈 정보를 가지고 새로운 dict 생성\n",
    "    train_data = {\n",
    "        'images': train_images,\n",
    "        'annotations': train_annotations,\n",
    "        'categories': categories,\n",
    "    }\n",
    "\n",
    "    val_data = {\n",
    "        'images': val_images,\n",
    "        'annotations': val_annotations,\n",
    "        'categories': categories,\n",
    "    }\n",
    "\n",
    "\n",
    "    # 새롭게 만든 dict로 train/val json 파일 생성\n",
    "    os.makedirs(new_dataset_dir+f'/{fold_ind}', exist_ok=True)\n",
    "\n",
    "    new_train_json = os.path.join(new_dataset_dir, f'{fold_ind}','train.json')\n",
    "    new_val_json = os.path.join(new_dataset_dir,f'{fold_ind}', 'val.json')\n",
    "    copy_test_json = os.path.join(new_dataset_dir, f'{fold_ind}','test.json')\n",
    "\n",
    "    #train.json 새롭게 생성\n",
    "    with open(new_train_json, 'w') as train_writer:\n",
    "        json.dump(train_data, train_writer)\n",
    "\n",
    "    #val.json 새롭게 생성\n",
    "    with open(new_val_json, 'w') as val_writer:\n",
    "        json.dump(val_data, val_writer)\n",
    "\n",
    "    # train/val 이미지 파일 분리 복사\n",
    "    os.makedirs(os.path.join(new_dataset_dir, f'{fold_ind}','train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(new_dataset_dir, f'{fold_ind}','val'), exist_ok=True)\n",
    "\n",
    "    # train 해당 파일 복사\n",
    "    for train_img_info in train_images:\n",
    "        from_copy_train_img = os.path.join(origin_dataset_dir, train_img_info['file_name'])\n",
    "        to_copy_train_img = os.path.join(new_dataset_dir, f'{fold_ind}',train_img_info['file_name'])\n",
    "        shutil.copyfile(from_copy_train_img, to_copy_train_img)\n",
    "        \n",
    "    # val 해당 파일 복사\n",
    "    for val_img_info in val_images:\n",
    "        origin_id = os.path.join('train', val_img_info['file_name'].split('/')[1])\n",
    "        from_copy_val_img = os.path.join(origin_dataset_dir, origin_id)\n",
    "        to_copy_val_img = os.path.join(new_dataset_dir,f'{fold_ind}', val_img_info['file_name'])\n",
    "        shutil.copyfile(from_copy_val_img, to_copy_val_img)\n",
    "    \n",
    "    #기존 파일에서 test json파일 복사\n",
    "    shutil.copyfile(os.path.join(origin_dataset_dir, 'test.json'), copy_test_json)\n",
    "\n",
    "    # test 이미지 폴더 전체 복사\n",
    "    shutil.copytree(os.path.join(origin_dataset_dir, 'test'), os.path.join(new_dataset_dir,f'{fold_ind}', 'test'))\n",
    "\n",
    "\n",
    "    print(f'train 이미지 파일 개수({int((1-val_ratio)*100)}%):{num_train}')\n",
    "    print('new_dataset_train 파일 개수:{}'.format(len(os.listdir(os.path.join(new_dataset_dir,f'{fold_ind}','train')))))\n",
    "    print(f'val 이미지 파일 개수({int(val_ratio*100)}%):{num_val}')\n",
    "    print('new_dataset_val 파일 개수:{}'.format(len(os.listdir(os.path.join(new_dataset_dir,f'{fold_ind}', 'val')))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
