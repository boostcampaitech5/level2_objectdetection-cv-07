{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import detectron2\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import math\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format: register_coco_instances(name, metadata, json_file, image_root):\n",
    "# name = dataset name\n",
    "# once you have registered the dataset, you can use the name of the dataset in cfg.DATASETS.{TRAIN,TEST}\n",
    "register_coco_instances(name='coco_train1', metadata={}, json_file='../../dataset/train.json', image_root='../../dataset/')\n",
    "register_coco_instances(name='coco_test1',  metadata={}, json_file='../../dataset/test.json',  image_root='../../dataset/')\n",
    "\n",
    "# revise metadata\n",
    "MetadataCatalog.get('coco_train1').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Revise Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml'))\n",
    "\n",
    "# revise config file\n",
    "cfg.DATASETS.TRAIN = ('coco_train1', {}, '../../dataset/train.json', '../../dataset/')\n",
    "cfg.DATASETS.TEST  = ('coco_test1', {}, '../../dataset/test.json', '../../dataset/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a batch of 16 images (Only Used For group_image Helper Method) and Generate Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/04 16:27:42 d2.data.datasets.coco]: Loaded 4883 images in COCO format from ../../dataset/train.json\n"
     ]
    }
   ],
   "source": [
    "# Takes 10 minutes to complete\n",
    "# If you're hesitant to wait, then just load pickle the file I provided to you. No need to run this cell!\n",
    "import pickle\n",
    "\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"coco_train1\")\n",
    "dataset_dicts = DatasetCatalog.get(\"coco_train1\")\n",
    "\n",
    "images_dataset  = []\n",
    "image_collector = []\n",
    "for idx, data in enumerate(dataset_dicts): # takes 10 minutes\n",
    "    img_data = cv2.imread(data[\"file_name\"]) \n",
    "    visualizer = Visualizer(img_data[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.3)\n",
    "    vis = visualizer.draw_dataset_dict(data)\n",
    "    image = vis.get_image()[:, :, ::-1]\n",
    "    image_collector.append(image)\n",
    "    \n",
    "    if idx % 16 == 0:\n",
    "        images_dataset.append(image_collector)\n",
    "        image_collector = []\n",
    "\n",
    "with open('image_dataset.txt', 'wb') as f: # create the file in the current directory\n",
    "    pickle.dump(images_dataset, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306\n"
     ]
    }
   ],
   "source": [
    "with open('image_dataset.txt', 'rb') as f:\n",
    "    loaded_pickle = pickle.load(f)\n",
    "\n",
    "# if the output is 306, your good to go!\n",
    "print(len(loaded_pickle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output of dataset_dicts\n",
    "# {'file_name': '../../dataset/train/4183.jpg', 'height': 1024, 'width': 1024, 'image_id': 4183, 'annotations': [{'iscrowd': 0, 'bbox': [63.3, 235.9, 706.0, 559.0], 'category_id': 1, 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Helper Methods!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group image\n",
    "def group_image(images_dataset, idx):\n",
    "    '''\n",
    "    idx 0: 0000\n",
    "    idx 1: 0001~0016\n",
    "    idx 2: 0017~0032\n",
    "    '''\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12,12), dpi=120)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    num = 0\n",
    "    if idx == 0:\n",
    "        picture_number = [0]\n",
    "    else:\n",
    "        picture_number = [i for i in range((idx*16)-15, ((idx+1)*16)-15)]\n",
    "    for idx, (i, pic_num) in enumerate(zip(images_dataset[idx], picture_number), start=num):\n",
    "        pic_num = str(pic_num).zfill(4)\n",
    "        i = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
    "        axes[idx].imshow(i)\n",
    "        axes[idx].set_title(f\"train/{pic_num}.jpg\")\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "# individual image\n",
    "def individual_image(train_dataset, id:int): \n",
    "    original_number = id \n",
    "    id = math.ceil(id/16)\n",
    "    picture_number = [i for i in range((id*16)-15, ((id+1)*16)-15)]\n",
    "    train_dataset = train_dataset[id]\n",
    "    for idx, data in enumerate(train_dataset):\n",
    "        if idx == original_number - picture_number[0]:\n",
    "            data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure()\n",
    "            plt.title(f\"train/{str(original_number).zfill(4)}.jpg\")\n",
    "            plt.imshow(data)\n",
    "            plt.axis('off')\n",
    "\n",
    "# random image\n",
    "def random_image(number_of_images:int=5):\n",
    "    my_dataset_train_metadata = MetadataCatalog.get(\"coco_train1\")\n",
    "    dataset_dicts = DatasetCatalog.get(\"coco_train1\")\n",
    "    for data in random.sample(dataset_dicts, number_of_images):\n",
    "        img_data = cv2.imread(data[\"file_name\"]) \n",
    "        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n",
    "        visualizer = Visualizer(img_data[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n",
    "        vis = visualizer.draw_dataset_dict(data)\n",
    "        image = vis.get_image()[:, :, ::-1]\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"{data['file_name'][-14:]}\")\n",
    "        plt.axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# random images (it will show N images)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m random_image(\u001b[39m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_image' is not defined"
     ]
    }
   ],
   "source": [
    "# random images (it will show N images)\n",
    "random_image(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'individual_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# individual image (select from 0000~4882)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m individual_image(loaded_pickle, \u001b[39m1234\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'individual_image' is not defined"
     ]
    }
   ],
   "source": [
    "# individual image (select from 0000~4882)\n",
    "individual_image(loaded_pickle, 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'group_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# group image (select from 0~305)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# 0 = 0000 (only)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# 1 = 0001 ~ 0016 \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# 2 = 0017 ~ 0032 \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# and so on..\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m group_image(loaded_pickle, \u001b[39m78\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'group_image' is not defined"
     ]
    }
   ],
   "source": [
    "# group image (select from 0~305)\n",
    "# 0 = 0000 (only)\n",
    "# 1 = 0001 ~ 0016 \n",
    "# 2 = 0017 ~ 0032 \n",
    "# and so on..\n",
    "group_image(loaded_pickle, 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
