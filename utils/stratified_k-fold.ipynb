{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    1 ... 4881 4881 4881]\n",
      "  [0 3 7 ... 7 1 7]\n",
      " TEST: [   6   13   13 ... 4882 4882 4882]\n",
      "  [1 6 7 ... 0 1 1]\n",
      "TRAIN: [   0    1    1 ... 4882 4882 4882]\n",
      "  [0 3 7 ... 0 1 1]\n",
      " TEST: [   5    5    5 ... 4876 4876 4878]\n",
      "  [7 0 0 ... 0 2 0]\n",
      "TRAIN: [   0    3    3 ... 4882 4882 4882]\n",
      "  [0 2 6 ... 0 1 1]\n",
      " TEST: [   1    1    1 ... 4877 4877 4880]\n",
      "  [3 7 4 ... 7 7 0]\n",
      "TRAIN: [   1    1    1 ... 4882 4882 4882]\n",
      "  [3 7 4 ... 0 1 1]\n",
      " TEST: [   0    3    3 ... 4881 4881 4881]\n",
      "  [0 2 6 ... 7 1 7]\n",
      "TRAIN: [   0    1    1 ... 4882 4882 4882]\n",
      "  [0 3 7 ... 0 1 1]\n",
      " TEST: [   4    4    4 ... 4868 4872 4872]\n",
      "  [1 1 1 ... 2 4 6]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# load json: modify the path to your own ‘train.json’ file\n",
    "annotation = '/opt/ml/dataset/train.json'\n",
    "\n",
    "with open(annotation) as f: data = json.load(f)\n",
    "\n",
    "var = [(ann['image_id'], ann['category_id']) for ann in data['annotations']]\n",
    "X = np.ones((len(data['annotations']),1))\n",
    "y = np.array([v[1] for v in var])\n",
    "groups = np.array([v[0] for v in var])\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=411)\n",
    "\n",
    "for train_idx, val_idx in cv.split(X, y, groups):\n",
    "    print(\"TRAIN:\", groups[train_idx])\n",
    "    print(\" \", y[train_idx])\n",
    "    print(\" TEST:\", groups[val_idx])\n",
    "    print(\" \", y[val_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General trash</th>\n",
       "      <th>Paper</th>\n",
       "      <th>Paper pack</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Glass</th>\n",
       "      <th>Plastic</th>\n",
       "      <th>Styrofoam</th>\n",
       "      <th>Plastic bag</th>\n",
       "      <th>Battery</th>\n",
       "      <th>Clothing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training set</th>\n",
       "      <td>17.14%</td>\n",
       "      <td>27.45%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train - fold0</th>\n",
       "      <td>16.96%</td>\n",
       "      <td>27.45%</td>\n",
       "      <td>3.79%</td>\n",
       "      <td>4.13%</td>\n",
       "      <td>4.48%</td>\n",
       "      <td>12.61%</td>\n",
       "      <td>5.51%</td>\n",
       "      <td>22.28%</td>\n",
       "      <td>0.77%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val - fold0</th>\n",
       "      <td>17.85%</td>\n",
       "      <td>27.42%</td>\n",
       "      <td>4.23%</td>\n",
       "      <td>3.70%</td>\n",
       "      <td>3.26%</td>\n",
       "      <td>13.15%</td>\n",
       "      <td>5.25%</td>\n",
       "      <td>22.77%</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train - fold1</th>\n",
       "      <td>17.14%</td>\n",
       "      <td>27.24%</td>\n",
       "      <td>4.01%</td>\n",
       "      <td>3.98%</td>\n",
       "      <td>4.28%</td>\n",
       "      <td>12.77%</td>\n",
       "      <td>5.38%</td>\n",
       "      <td>22.32%</td>\n",
       "      <td>0.67%</td>\n",
       "      <td>2.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val - fold1</th>\n",
       "      <td>17.12%</td>\n",
       "      <td>28.17%</td>\n",
       "      <td>3.41%</td>\n",
       "      <td>4.26%</td>\n",
       "      <td>4.12%</td>\n",
       "      <td>12.51%</td>\n",
       "      <td>5.72%</td>\n",
       "      <td>22.57%</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>1.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train - fold2</th>\n",
       "      <td>17.31%</td>\n",
       "      <td>27.39%</td>\n",
       "      <td>3.83%</td>\n",
       "      <td>4.08%</td>\n",
       "      <td>4.13%</td>\n",
       "      <td>12.80%</td>\n",
       "      <td>5.14%</td>\n",
       "      <td>22.68%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>1.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val - fold2</th>\n",
       "      <td>16.42%</td>\n",
       "      <td>27.68%</td>\n",
       "      <td>4.05%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.70%</td>\n",
       "      <td>12.36%</td>\n",
       "      <td>6.76%</td>\n",
       "      <td>21.12%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train - fold3</th>\n",
       "      <td>17.30%</td>\n",
       "      <td>27.47%</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>4.06%</td>\n",
       "      <td>4.22%</td>\n",
       "      <td>12.63%</td>\n",
       "      <td>5.49%</td>\n",
       "      <td>22.39%</td>\n",
       "      <td>0.63%</td>\n",
       "      <td>1.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val - fold3</th>\n",
       "      <td>16.50%</td>\n",
       "      <td>27.36%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>3.99%</td>\n",
       "      <td>4.33%</td>\n",
       "      <td>13.07%</td>\n",
       "      <td>5.33%</td>\n",
       "      <td>22.30%</td>\n",
       "      <td>0.92%</td>\n",
       "      <td>2.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train - fold4</th>\n",
       "      <td>16.97%</td>\n",
       "      <td>27.67%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>3.97%</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>12.77%</td>\n",
       "      <td>5.76%</td>\n",
       "      <td>22.20%</td>\n",
       "      <td>0.68%</td>\n",
       "      <td>2.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val - fold4</th>\n",
       "      <td>17.84%</td>\n",
       "      <td>26.48%</td>\n",
       "      <td>3.85%</td>\n",
       "      <td>4.38%</td>\n",
       "      <td>4.84%</td>\n",
       "      <td>12.50%</td>\n",
       "      <td>4.15%</td>\n",
       "      <td>23.11%</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>2.11%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              General trash   Paper Paper pack  Metal  Glass Plastic  \\\n",
       "training set         17.14%  27.45%      3.88%  4.04%  4.24%  12.72%   \n",
       "train - fold0        16.96%  27.45%      3.79%  4.13%  4.48%  12.61%   \n",
       "val - fold0          17.85%  27.42%      4.23%  3.70%  3.26%  13.15%   \n",
       "train - fold1        17.14%  27.24%      4.01%  3.98%  4.28%  12.77%   \n",
       "val - fold1          17.12%  28.17%      3.41%  4.26%  4.12%  12.51%   \n",
       "train - fold2        17.31%  27.39%      3.83%  4.08%  4.13%  12.80%   \n",
       "val - fold2          16.42%  27.68%      4.05%  3.88%  4.70%  12.36%   \n",
       "train - fold3        17.30%  27.47%      3.87%  4.06%  4.22%  12.63%   \n",
       "val - fold3          16.50%  27.36%      3.88%  3.99%  4.33%  13.07%   \n",
       "train - fold4        16.97%  27.67%      3.88%  3.97%  4.10%  12.77%   \n",
       "val - fold4          17.84%  26.48%      3.85%  4.38%  4.84%  12.50%   \n",
       "\n",
       "              Styrofoam Plastic bag Battery Clothing  \n",
       "training set      5.46%      22.37%   0.69%    2.02%  \n",
       "train - fold0     5.51%      22.28%   0.77%    2.02%  \n",
       "val - fold0       5.25%      22.77%   0.35%    2.02%  \n",
       "train - fold1     5.38%      22.32%   0.67%    2.20%  \n",
       "val - fold1       5.72%      22.57%   0.73%    1.38%  \n",
       "train - fold2     5.14%      22.68%   0.69%    1.94%  \n",
       "val - fold2       6.76%      21.12%   0.69%    2.35%  \n",
       "train - fold3     5.49%      22.39%   0.63%    1.95%  \n",
       "val - fold3       5.33%      22.30%   0.92%    2.32%  \n",
       "train - fold4     5.76%      22.20%   0.68%    2.00%  \n",
       "val - fold4       4.15%      23.11%   0.73%    2.11%  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check distribution\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def get_distribution(y):\n",
    "    y_distr = Counter(y)\n",
    "    y_vals_sum = sum(y_distr.values())\n",
    "\n",
    "    return [f'{y_distr[i]/y_vals_sum:.2%}' for i in range(np.max(y) +1)]\n",
    "\n",
    "distrs = [get_distribution(y)]\n",
    "index = ['training set']\n",
    "\n",
    "for fold_ind, (train_idx, val_idx) in enumerate(cv.split(X,y, groups)):\n",
    "    train_y, val_y = y[train_idx], y[val_idx]\n",
    "    train_gr, val_gr = groups[train_idx], groups[val_idx]\n",
    "\n",
    "    assert len(set(train_gr) & set(val_gr)) == 0 \n",
    "    distrs.append(get_distribution(train_y))\n",
    "\n",
    "    distrs.append(get_distribution(val_y))\n",
    "    index.append(f'train - fold{fold_ind}')\n",
    "    index.append(f'val - fold{fold_ind}')\n",
    "\n",
    "categories = [d['name'] for d in data['categories']]\n",
    "pd.DataFrame(distrs, index=index, columns = [categories[i] for i in range(np.max(y) + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 23136, 23137, 23138])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(cv.split(X,y, groups))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3909"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_gr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 이미지 파일 개수(80%):3914\n",
      "new_dataset_train 파일 개수:3914\n",
      "val 이미지 파일 개수(20%):969\n",
      "new_dataset_val 파일 개수:969\n",
      "train 이미지 파일 개수(80%):3906\n",
      "new_dataset_train 파일 개수:3906\n",
      "val 이미지 파일 개수(20%):977\n",
      "new_dataset_val 파일 개수:977\n",
      "train 이미지 파일 개수(80%):3901\n",
      "new_dataset_train 파일 개수:3901\n",
      "val 이미지 파일 개수(20%):982\n",
      "new_dataset_val 파일 개수:982\n",
      "train 이미지 파일 개수(80%):3902\n",
      "new_dataset_train 파일 개수:3902\n",
      "val 이미지 파일 개수(20%):981\n",
      "new_dataset_val 파일 개수:981\n",
      "train 이미지 파일 개수(80%):3909\n",
      "new_dataset_train 파일 개수:3909\n",
      "val 이미지 파일 개수(20%):974\n",
      "new_dataset_val 파일 개수:974\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "origin_dataset_dir = '/opt/ml/dataset'\n",
    "new_dataset_dir = '/opt/ml/test_dir'\n",
    "input_json_path = '/opt/ml/dataset/train.json' #train.json 파일 경로\n",
    "val_ratio = 0.2\n",
    "\n",
    "\n",
    "for fold_ind, (train_idx, val_idx) in enumerate(cv.split(X,y, groups)):\n",
    "#json 파일 불러오기\n",
    "    with open(input_json_path, 'r') as json_reader:\n",
    "        dataset = json.load(json_reader)\n",
    "\n",
    "    images = dataset['images'] # dict에서 (key:images)의 values 불러오기\n",
    "    categories = dataset['categories']# dict에서 (key:catagories)의 values 불러오기\n",
    "    annotations = dataset['annotations']# dict에서 (key:annotations)의 values 불러오기\n",
    "    \n",
    "    train_gr, val_gr = groups[train_idx], groups[val_idx]\n",
    "\n",
    "    # image_ids = [x.get('id') for x in images] # get함수를 통해 dict에서 id값 추출\n",
    "    # image_ids.sort() # 정렬\n",
    "    # random.shuffle(image_ids) # 인덱스 섞기\n",
    "\n",
    "    # num_val = int(len(image_ids) * val_ratio)\n",
    "    # num_train = len(image_ids) - num_val\n",
    "\n",
    "    image_ids_val, image_ids_train = set(val_gr), set(train_gr)\n",
    "\n",
    "    num_train = len(image_ids_train)\n",
    "    num_val = len(image_ids_val)\n",
    "\n",
    "    #Image_id를 기준으로 train/val 나누기\n",
    "    train_images = [x for x in images if x.get('id') in image_ids_train]\n",
    "    val_images = [x for x in images if x.get('id') in image_ids_val]\n",
    "    train_annotations = [x for x in annotations if x.get('image_id') in image_ids_train]\n",
    "    val_annotations = [x for x in annotations if x.get('image_id') in image_ids_val]\n",
    "\n",
    "    #file_name 수정\n",
    "    for info in val_images:\n",
    "        name = info['file_name'].split('/')[1]\n",
    "        info['file_name'] = os.path.join('val',name)\n",
    "        \n",
    "    #나눈 정보를 가지고 새로운 dict 생성\n",
    "    train_data = {\n",
    "        'images': train_images,\n",
    "        'annotations': train_annotations,\n",
    "        'categories': categories,\n",
    "    }\n",
    "\n",
    "    val_data = {\n",
    "        'images': val_images,\n",
    "        'annotations': val_annotations,\n",
    "        'categories': categories,\n",
    "    }\n",
    "\n",
    "\n",
    "    # 새롭게 만든 dict로 train/val json 파일 생성\n",
    "    os.makedirs(new_dataset_dir+f'/{fold_ind}', exist_ok=True)\n",
    "\n",
    "    new_train_json = os.path.join(new_dataset_dir, f'{fold_ind}','train.json')\n",
    "    new_val_json = os.path.join(new_dataset_dir,f'{fold_ind}', 'val.json')\n",
    "    copy_test_json = os.path.join(new_dataset_dir, f'{fold_ind}','test.json')\n",
    "\n",
    "    #train.json 새롭게 생성\n",
    "    with open(new_train_json, 'w') as train_writer:\n",
    "        json.dump(train_data, train_writer)\n",
    "\n",
    "    #val.json 새롭게 생성\n",
    "    with open(new_val_json, 'w') as val_writer:\n",
    "        json.dump(val_data, val_writer)\n",
    "\n",
    "    # train/val 이미지 파일 분리 복사\n",
    "    os.makedirs(os.path.join(new_dataset_dir, f'{fold_ind}','train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(new_dataset_dir, f'{fold_ind}','val'), exist_ok=True)\n",
    "\n",
    "    # train 해당 파일 복사\n",
    "    for train_img_info in train_images:\n",
    "        from_copy_train_img = os.path.join(origin_dataset_dir, train_img_info['file_name'])\n",
    "        to_copy_train_img = os.path.join(new_dataset_dir, f'{fold_ind}',train_img_info['file_name'])\n",
    "        shutil.copyfile(from_copy_train_img, to_copy_train_img)\n",
    "        \n",
    "    # val 해당 파일 복사\n",
    "    for val_img_info in val_images:\n",
    "        origin_id = os.path.join('train', val_img_info['file_name'].split('/')[1])\n",
    "        from_copy_val_img = os.path.join(origin_dataset_dir, origin_id)\n",
    "        to_copy_val_img = os.path.join(new_dataset_dir,f'{fold_ind}', val_img_info['file_name'])\n",
    "        shutil.copyfile(from_copy_val_img, to_copy_val_img)\n",
    "    \n",
    "    #기존 파일에서 test json파일 복사\n",
    "    shutil.copyfile(os.path.join(origin_dataset_dir, 'test.json'), copy_test_json)\n",
    "\n",
    "    # test 이미지 폴더 전체 복사\n",
    "    shutil.copytree(os.path.join(origin_dataset_dir, 'test'), os.path.join(new_dataset_dir,f'{fold_ind}', 'test'))\n",
    "\n",
    "\n",
    "    print(f'train 이미지 파일 개수({int((1-val_ratio)*100)}%):{num_train}')\n",
    "    print('new_dataset_train 파일 개수:{}'.format(len(os.listdir(os.path.join(new_dataset_dir,f'{fold_ind}','train')))))\n",
    "    print(f'val 이미지 파일 개수({int(val_ratio*100)}%):{num_val}')\n",
    "    print('new_dataset_val 파일 개수:{}'.format(len(os.listdir(os.path.join(new_dataset_dir,f'{fold_ind}', 'val')))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection2",
   "language": "python",
   "name": "detection2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
